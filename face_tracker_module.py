import cv2
import numpy as np
import threading
import time
from collections import deque
import os
from datetime import datetime

# å˜—è©¦å°å…¥ DeepFace
try:
    from deepface import DeepFace
    DEEPFACE_AVAILABLE = True
except ImportError:
    DEEPFACE_AVAILABLE = False
    print("âš ï¸  DeepFace æœªå®‰è£ï¼Œå°å­©ä¿è­·åŠŸèƒ½ä¸å¯ç”¨")
    print("   å®‰è£æ–¹å¼: pip install deepface")

# å˜—è©¦å°å…¥MediaPipe
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("å»ºè­°å®‰è£MediaPipeä»¥ç²å¾—æ›´å¥½æ•ˆæœ: pip install mediapipe")

class VideoRecorder:
    """å½±ç‰‡éŒ„è£½ç®¡ç†å™¨"""
    def __init__(self):
        self.recording = False
        self.video_writer = None
        self.output_filename = None
        self.start_time = None
        self.frame_count = 0
        
        # éŒ„è£½è¨­å®š
        self.fps = 30
        self.frame_size = (640, 480)
        self.codec = cv2.VideoWriter_fourcc(*'mp4v')
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir = "recorded_videos"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
    
    def start_recording(self, frame_size=None):
        """é–‹å§‹éŒ„è£½"""
        if self.recording:
            print("âš ï¸ å·²åœ¨éŒ„è£½ä¸­")
            return False
        
        if frame_size:
            self.frame_size = frame_size
        
        # ç”Ÿæˆæª”æ¡ˆåç¨±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_filename = os.path.join(self.output_dir, f"mosaic_video_{timestamp}.mp4")
        
        # åˆå§‹åŒ–VideoWriter
        self.video_writer = cv2.VideoWriter(
            self.output_filename,
            self.codec,
            self.fps,
            self.frame_size
        )
        
        if not self.video_writer.isOpened():
            print("âŒ ç„¡æ³•åˆå§‹åŒ–å½±ç‰‡å¯«å…¥å™¨")
            return False
        
        self.recording = True
        self.start_time = time.time()
        self.frame_count = 0
        print(f"ğŸ¬ é–‹å§‹éŒ„è£½: {self.output_filename}")
        return True
    
    def write_frame(self, frame):
        """å¯«å…¥ä¸€å¹€"""
        if not self.recording or self.video_writer is None:
            return
        
        # ç¢ºä¿å¹€å¤§å°æ­£ç¢º
        if frame.shape[:2] != (self.frame_size[1], self.frame_size[0]):
            frame = cv2.resize(frame, self.frame_size)
        
        self.video_writer.write(frame)
        self.frame_count += 1
    
    def stop_recording(self):
        """åœæ­¢éŒ„è£½"""
        if not self.recording:
            print("âš ï¸ ç›®å‰æœªåœ¨éŒ„è£½")
            return None
        
        self.recording = False
        
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
        
        duration = time.time() - self.start_time if self.start_time else 0
        
        print(f"ğŸ¯ éŒ„è£½å®Œæˆ!")
        print(f"   æª”æ¡ˆ: {self.output_filename}")
        print(f"   æ™‚é•·: {duration:.1f} ç§’")
        print(f"   å¹€æ•¸: {self.frame_count}")
        print(f"   å¹³å‡FPS: {self.frame_count/duration:.1f}" if duration > 0 else "")
        
        return self.output_filename
    
    def get_recording_info(self):
        """ç²å–éŒ„è£½è³‡è¨Š"""
        if not self.recording:
            return None
        
        duration = time.time() - self.start_time if self.start_time else 0
        return {
            'filename': os.path.basename(self.output_filename),
            'duration': duration,
            'frame_count': self.frame_count,
            'fps': self.frame_count / duration if duration > 0 else 0
        }

class OptimizedFaceTracker:
    def __init__(self):
        # YOLO è¨­å®š
        self.yolo_model = None
        self.yolo_available = False
        self.init_yolo()
        
        # MediaPipeè¨­å®š
        if MEDIAPIPE_AVAILABLE:
            self.mp_face_detection = mp.solutions.face_detection
            self.face_detection = self.mp_face_detection.FaceDetection(
                model_selection=0, min_detection_confidence=0.4 
            )
        
        # Haaråˆ†é¡å™¨
        self.frontal_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # æª¢æ¸¬ç®¡ç†
        self.last_detection_time = time.time()
        self.detection_interval = 0.05  # æ¯50msé€²è¡Œä¸€æ¬¡æª¢æ¸¬
        
        # è‡‰éƒ¨ä½ç½®ç·©å­˜
        self.face_history = deque(maxlen=5)  # ä¿å­˜æœ€è¿‘5å¹€çš„æª¢æ¸¬çµæœ
        self.smooth_faces = []  # å¹³æ»‘å¾Œçš„è‡‰éƒ¨ä½ç½®
        
        # æ€§èƒ½å„ªåŒ–
        self.frame_skip = 0
        self.max_frame_skip = 2
        
        # å®‰å…¨å€åŸŸï¼ˆæ“´å¤§çš„é®æ“‹ç¯„åœï¼‰
        self.safety_margin = 1.3  # æ“´å¤§30%
        
        # æª¢æ¸¬æ–¹æ³•å„ªå…ˆç´š
        self.detection_method = 'yolo'  # 'yolo', 'mediapipe', 'haar'
        
        # å°å­©ä¿è­·åŠŸèƒ½
        self.child_protection_enabled = False
        self.age_threshold = 18  # 18æ­²ä»¥ä¸‹è¦–ç‚ºå°å­©
        self.face_age_cache = {}  # ç·©å­˜å¹´é½¡æª¢æ¸¬çµæœ
        self.age_detection_interval = 2.0  # æ¯2ç§’é‡æ–°æª¢æ¸¬å¹´é½¡
        self.last_age_detection = {}  # è¨˜éŒ„æ¯å¼µè‡‰çš„æœ€å¾Œæª¢æ¸¬æ™‚é–“
        
        # DeepFace è¨­å®š
        if DEEPFACE_AVAILABLE:
            self.deepface_backend = 'opencv'  # ä½¿ç”¨ opencv å¾Œç«¯ä»¥æé«˜é€Ÿåº¦
            print("âœ“ DeepFace å·²è¼‰å…¥ï¼Œå°å­©ä¿è­·åŠŸèƒ½å¯ç”¨")
        
    def init_yolo(self):
        """åˆå§‹åŒ– YOLO æ¨¡å‹"""
        try:
            model_path = 'yolov11n-face.onnx'
            if os.path.exists(model_path):
                self.yolo_model = cv2.dnn.readNetFromONNX(model_path)
                self.yolo_available = True
                print("âœ“ YOLOv11n-face æ¨¡å‹è¼‰å…¥æˆåŠŸ")
                
                # è¨­å®šé‹ç®—å¾Œç«¯
                if cv2.cuda.getCudaEnabledDeviceCount() > 0:
                    self.yolo_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
                    self.yolo_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
                    print("âœ“ ä½¿ç”¨ CUDA åŠ é€Ÿ")
                else:
                    self.yolo_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                    self.yolo_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
                    print("âœ“ ä½¿ç”¨ CPU é‹ç®—")
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ° YOLO æ¨¡å‹æª”æ¡ˆ: {model_path}")
                print("  è«‹ç¢ºä¿ yolov11n-face.onnx åœ¨ç¨‹å¼åŒç›®éŒ„ä¸‹")
        except Exception as e:
            print(f"âš ï¸ YOLO æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            self.yolo_available = False
    
    def detect_faces_yolo(self, frame):
        """ä½¿ç”¨ YOLO æª¢æ¸¬äººè‡‰"""
        if not self.yolo_available:
            return []
        
        try:
            height, width = frame.shape[:2]
            
            # é è™•ç†åœ–åƒ
            blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)
            
            # æ¨ç†
            self.yolo_model.setInput(blob)
            outputs = self.yolo_model.forward()
            
            # è™•ç†è¼¸å‡º
            faces = []
            confidences = []
            
            # YOLOv11 è¼¸å‡ºæ ¼å¼è™•ç†
            # é€šå¸¸æ ¼å¼æ˜¯ [1, num_detections, 85] æˆ– [num_detections, 85]
            if len(outputs.shape) == 3:
                outputs = outputs[0]
            
            # è½‰ç½®å¦‚æœéœ€è¦ï¼ˆæŸäº›ç‰ˆæœ¬è¼¸å‡ºæ˜¯ [85, num_detections]ï¼‰
            if outputs.shape[0] in [5, 6, 85] and outputs.shape[1] > outputs.shape[0]:
                outputs = outputs.T
            
            # è§£ææª¢æ¸¬çµæœ
            for detection in outputs:
                if len(detection) >= 5:
                    # YOLOv11 æ ¼å¼é€šå¸¸æ˜¯ [x_center, y_center, width, height, confidence, ...]
                    confidence = float(detection[4])
                    if confidence > 0.3:  # é™ä½ä¿¡å¿ƒåº¦é–¾å€¼
                        # ç²å–é‚Šç•Œæ¡†åº§æ¨™ï¼ˆç›¸å°æ–¼640x640ï¼‰
                        x_center = detection[0]
                        y_center = detection[1]
                        box_width = detection[2]
                        box_height = detection[3]
                        
                        # è½‰æ›å›åŸå§‹åœ–åƒåº§æ¨™
                        scale_x = width / 640.0
                        scale_y = height / 640.0
                        
                        x_center = x_center * scale_x
                        y_center = y_center * scale_y
                        w = box_width * scale_x
                        h = box_height * scale_y
                        
                        # è½‰æ›ç‚ºå·¦ä¸Šè§’åº§æ¨™
                        x = int(x_center - w / 2)
                        y = int(y_center - h / 2)
                        w = int(w)
                        h = int(h)
                        
                        # ç¢ºä¿åº§æ¨™åœ¨åœ–åƒç¯„åœå…§
                        x = max(0, x)
                        y = max(0, y)
                        w = min(width - x, w)
                        h = min(height - y, h)
                        
                        if w > 20 and h > 20:
                            faces.append([x, y, w, h])
                            confidences.append(confidence)
            
            # NMS å»é™¤é‡è¤‡æª¢æ¸¬
            if len(faces) > 0:
                indices = cv2.dnn.NMSBoxes(faces, confidences, 0.3, 0.4)
                if len(indices) > 0:
                    if isinstance(indices, np.ndarray):
                        indices = indices.flatten()
                    return [tuple(faces[i]) for i in indices]
            
            return []
            
        except Exception as e:
            print(f"YOLO æª¢æ¸¬éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def expand_face_region(self, face_rect, frame_shape, margin=None):
        """æ“´å¤§äººè‡‰å€åŸŸä»¥æä¾›å®‰å…¨é‚Šç•Œ"""
        if margin is None:
            margin = self.safety_margin
            
        x, y, w, h = face_rect
        frame_h, frame_w = frame_shape[:2]
        
        # è¨ˆç®—æ“´å±•å°ºå¯¸
        new_w = int(w * margin)
        new_h = int(h * margin)
        
        # è¨ˆç®—æ–°çš„å·¦ä¸Šè§’ä½ç½®ï¼ˆä¿æŒä¸­å¿ƒé»ï¼‰
        new_x = max(0, x - (new_w - w) // 2)
        new_y = max(0, y - (new_h - h) // 2)
        
        # ç¢ºä¿ä¸è¶…å‡ºæ¡†æ¶é‚Šç•Œ
        new_w = min(new_w, frame_w - new_x)
        new_h = min(new_h, frame_h - new_y)
        
        return (new_x, new_y, new_w, new_h)
    
    def smooth_face_positions(self, current_faces):
        """å¹³æ»‘è‡‰éƒ¨ä½ç½®ä»¥æ¸›å°‘æŠ–å‹•"""
        if not current_faces:
            return []
        
        # å°‡ç•¶å‰æª¢æ¸¬çµæœåŠ å…¥æ­·å²
        self.face_history.append(current_faces)
        
        if len(self.face_history) < 2:
            return current_faces
        
        # è¨ˆç®—å¹³æ»‘ä½ç½®
        smoothed_faces = []
        
        for i, face in enumerate(current_faces):
            x, y, w, h = face
            
            # æ‰¾åˆ°æ­·å²ä¸­æœ€æ¥è¿‘çš„è‡‰éƒ¨
            smooth_x, smooth_y, smooth_w, smooth_h = x, y, w, h
            weight_sum = 1.0
            
            for j, history_faces in enumerate(self.face_history):
                if j == len(self.face_history) - 1:  # è·³éç•¶å‰å¹€
                    continue
                
                # æ¬Šé‡éš¨æ™‚é–“éæ¸›
                weight = 0.5 ** (len(self.face_history) - j - 1)
                
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„è‡‰
                min_dist = float('inf')
                best_match = None
                
                for hist_face in history_faces:
                    hx, hy, hw, hh = hist_face
                    dist = np.sqrt((x - hx)**2 + (y - hy)**2)
                    
                    if dist < min_dist and dist < 100:  # æœ€å¤§åŒ¹é…è·é›¢
                        min_dist = dist
                        best_match = hist_face
                
                if best_match is not None:
                    hx, hy, hw, hh = best_match
                    smooth_x += hx * weight
                    smooth_y += hy * weight
                    smooth_w += hw * weight
                    smooth_h += hh * weight
                    weight_sum += weight
            
            # è¨ˆç®—åŠ æ¬Šå¹³å‡
            smooth_x = int(smooth_x / weight_sum)
            smooth_y = int(smooth_y / weight_sum)
            smooth_w = int(smooth_w / weight_sum)
            smooth_h = int(smooth_h / weight_sum)
            
            smoothed_faces.append((smooth_x, smooth_y, smooth_w, smooth_h))
        
        return smoothed_faces
    
    def analyze_face_age(self, frame, face_rect):
        """ä½¿ç”¨ DeepFace åˆ†æå¹´é½¡"""
        if not DEEPFACE_AVAILABLE or not self.child_protection_enabled:
            return None
        
        try:
            x, y, w, h = face_rect
            
            # ç¨å¾®æ“´å¤§å€åŸŸä»¥ç¢ºä¿åŒ…å«å®Œæ•´çš„è‡‰
            padding = int(min(w, h) * 0.2)
            x_start = max(0, x - padding)
            y_start = max(0, y - padding)
            x_end = min(frame.shape[1], x + w + padding)
            y_end = min(frame.shape[0], y + h + padding)
            
            # æå–è‡‰éƒ¨å€åŸŸ
            face_img = frame[y_start:y_end, x_start:x_end]
            
            # ç¢ºä¿åœ–åƒå¤§å°è¶³å¤ 
            if face_img.shape[0] < 48 or face_img.shape[1] < 48:
                return None
            
            # ä½¿ç”¨ DeepFace åˆ†æå¹´é½¡
            result = DeepFace.analyze(
                img_path=face_img,
                actions=['age'],
                enforce_detection=False,
                detector_backend=self.deepface_backend,
                silent=True
            )
            
            # æå–å¹´é½¡
            if isinstance(result, list):
                age = result[0]['age']
            else:
                age = result['age']
            
            return age
            
        except Exception as e:
            # å¹´é½¡æª¢æ¸¬å¤±æ•—ï¼Œé»˜èªè¿”å› None
            return None
    
    def get_face_hash(self, face_rect):
        """ç”Ÿæˆè‡‰éƒ¨ä½ç½®çš„å“ˆå¸Œå€¼ç”¨æ–¼ç·©å­˜"""
        x, y, w, h = face_rect
        # ä½¿ç”¨ä¸­å¿ƒé»å’Œå¤§å°ä½œç‚ºæ¨™è­˜
        return f"{x+w//2}_{y+h//2}_{w}_{h}"
    
    def should_apply_mosaic(self, frame, face_rect):
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²å°è©²è‡‰éƒ¨æ‡‰ç”¨é¦¬è³½å…‹"""
        if not self.child_protection_enabled:
            # å¦‚æœæœªå•Ÿç”¨å°å­©ä¿è­·ï¼Œå°æ‰€æœ‰äººè‡‰æ‡‰ç”¨é¦¬è³½å…‹
            return True
        
        if not DEEPFACE_AVAILABLE:
            # å¦‚æœ DeepFace ä¸å¯ç”¨ï¼Œç‚ºå®‰å…¨èµ·è¦‹å°æ‰€æœ‰äººè‡‰æ‡‰ç”¨é¦¬è³½å…‹
            return True
        
        # ç”Ÿæˆè‡‰éƒ¨æ¨™è­˜
        face_hash = self.get_face_hash(face_rect)
        current_time = time.time()
        
        # æª¢æŸ¥ç·©å­˜
        if face_hash in self.face_age_cache:
            last_time = self.last_age_detection.get(face_hash, 0)
            # å¦‚æœåœ¨ç·©å­˜æ™‚é–“å…§ï¼Œä½¿ç”¨ç·©å­˜çµæœ
            if current_time - last_time < self.age_detection_interval:
                age = self.face_age_cache[face_hash]
                return age is None or age < self.age_threshold
        
        # åˆ†æå¹´é½¡
        age = self.analyze_face_age(frame, face_rect)
        
        # æ›´æ–°ç·©å­˜
        self.face_age_cache[face_hash] = age
        self.last_age_detection[face_hash] = current_time
        
        # æ¸…ç†èˆŠç·©å­˜ï¼ˆä¿ç•™æœ€è¿‘çš„50å€‹ï¼‰
        if len(self.face_age_cache) > 50:
            # æŒ‰æ™‚é–“æ’åºï¼Œåˆªé™¤æœ€èˆŠçš„
            sorted_faces = sorted(self.last_age_detection.items(), key=lambda x: x[1])
            for old_face, _ in sorted_faces[:len(sorted_faces)-50]:
                self.face_age_cache.pop(old_face, None)
                self.last_age_detection.pop(old_face, None)
        
        # å¦‚æœå¹´é½¡æª¢æ¸¬å¤±æ•—æˆ–å¹´é½¡å°æ–¼é–¾å€¼ï¼Œæ‡‰ç”¨é¦¬è³½å…‹
        return age is None or age < self.age_threshold
    
    def fast_detect_faces(self, frame):
        """å¿«é€Ÿäººè‡‰æª¢æ¸¬ï¼ˆæ”¯æ´å¤šç¨®æ–¹æ³•ï¼‰"""
        faces = []
        
        # æ ¹æ“šå„ªå…ˆç´šä½¿ç”¨ä¸åŒçš„æª¢æ¸¬æ–¹æ³•
        if self.detection_method == 'yolo' and self.yolo_available:
            faces = self.detect_faces_yolo(frame)
            if len(faces) > 0:
                return faces
        
        # ä½¿ç”¨MediaPipeï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if MEDIAPIPE_AVAILABLE and (self.detection_method == 'mediapipe' or len(faces) == 0):
            try:
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = self.face_detection.process(rgb_frame)
                
                if results.detections:
                    h, w = frame.shape[:2]
                    for detection in results.detections:
                        bbox = detection.location_data.relative_bounding_box
                        x = max(0, int(bbox.xmin * w))
                        y = max(0, int(bbox.ymin * h))
                        width = min(w - x, int(bbox.width * w))
                        height = min(h - y, int(bbox.height * h))
                        
                        if width > 15 and height > 15:
                            faces.append((x, y, width, height))
                    
                    if len(faces) > 0:
                        return faces
            except:
                pass
        
        # å¦‚æœé‚„æ˜¯æ²’æª¢æ¸¬åˆ°ï¼Œä½¿ç”¨å¿«é€ŸHaaræª¢æ¸¬
        if len(faces) == 0:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            # ä½¿ç”¨è¼ƒå¯¬é¬†çš„åƒæ•¸é€²è¡Œå¿«é€Ÿæª¢æ¸¬
            detected = self.frontal_cascade.detectMultiScale(
                gray, scaleFactor=1.1, minNeighbors=2, minSize=(20, 20)
            )
            faces.extend(detected)
        
        return faces
    
    def update_face_detection(self, frame):
        """æ›´æ–°äººè‡‰æª¢æ¸¬"""
        current_time = time.time()
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é€²è¡Œæ–°çš„æª¢æ¸¬
        if current_time - self.last_detection_time >= self.detection_interval:
            # é€²è¡Œæª¢æ¸¬
            faces = self.fast_detect_faces(frame)
            self.last_detection_time = current_time
            
            # å¹³æ»‘è‡‰éƒ¨ä½ç½®
            if faces is not None:
                faces = self.smooth_face_positions(faces)
            
            self.smooth_faces = faces
            return faces
        else:
            # è¿”å›ä¸Šæ¬¡æª¢æ¸¬çš„çµæœ
            return self.smooth_faces

def apply_smart_mosaic(image, faces, mosaic_size=15, style='pixelate', tracker=None):
    """æ™ºèƒ½é¦¬è³½å…‹æ‡‰ç”¨ï¼ˆæ”¯æ´å°å­©ä¿è­·åŠŸèƒ½ï¼‰"""
    for i, face in enumerate(faces):
        x, y, w, h = face
        
        # æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ‡‰ç”¨é¦¬è³½å…‹
        if tracker and hasattr(tracker, 'should_apply_mosaic'):
            if not tracker.should_apply_mosaic(image, face):
                # å¦‚æœæ˜¯å¤§äººä¸”å•Ÿç”¨å°å­©ä¿è­·ï¼Œè·³éé¦¬è³½å…‹
                continue
        
        # æ“´å¤§ä¿è­·å€åŸŸ
        padding = max(10, min(w, h) // 8)
        safe_x = max(0, x - padding)
        safe_y = max(0, y - padding)
        safe_w = min(image.shape[1] - safe_x, w + 2 * padding)
        safe_h = min(image.shape[0] - safe_y, h + 2 * padding)
        
        if safe_w <= 5 or safe_h <= 5:
            continue
        
        face_region = image[safe_y:safe_y+safe_h, safe_x:safe_x+safe_w].copy()
        
        if style == 'pixelate':
            block_size = max(2, min(mosaic_size, min(safe_w, safe_h) // 8))
            small = cv2.resize(face_region, (block_size, block_size), interpolation=cv2.INTER_LINEAR)
            mosaic = cv2.resize(small, (safe_w, safe_h), interpolation=cv2.INTER_NEAREST)
        elif style == 'blur':
            kernel_size = max(5, mosaic_size * 2 + 1)
            if kernel_size % 2 == 0:
                kernel_size += 1
            mosaic = cv2.GaussianBlur(face_region, (kernel_size, kernel_size), 0)
        else:  # 'black'
            mosaic = np.zeros_like(face_region)
        
        # æ‡‰ç”¨æ¼¸è®Šé‚Šç·£ä»¥æ¸›å°‘çªå…€æ„Ÿ
        if style != 'black':
            mask = np.ones((safe_h, safe_w, 3), dtype=np.float32)
            border_size = min(10, min(safe_w, safe_h) // 10)
            
            # å‰µå»ºæ¼¸è®Šé®ç½©
            for i in range(border_size):
                alpha = i / border_size
                mask[i, :] *= alpha
                mask[-(i+1), :] *= alpha
                mask[:, i] *= alpha
                mask[:, -(i+1)] *= alpha
            
            # æ··åˆåŸåœ–å’Œé¦¬è³½å…‹
            mosaic = (mosaic * mask + face_region * (1 - mask)).astype(np.uint8)
        
        image[safe_y:safe_y+safe_h, safe_x:safe_x+safe_w] = mosaic
    
    return image

def main():
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
        return
    
    # å„ªåŒ–æ”å½±æ©Ÿè¨­å®š
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    tracker = OptimizedFaceTracker()
    recorder = VideoRecorder()
    
    mosaic_size = 15
    mosaic_style = 'pixelate'
    
    print("\n=== é«˜æ€§èƒ½äººè‡£é¦¬è³½å…‹ (å„ªåŒ–ç‰ˆ + éŒ„å½±åŠŸèƒ½) ===")
    print("âœ“ YOLOv11n-face æ·±åº¦å­¸ç¿’æª¢æ¸¬")
    print("âœ“ ä½ç½®å¹³æ»‘ç®—æ³•")
    print("âœ“ å°å­©ä¿è­·åŠŸèƒ½")
    print("âœ“ é«˜é€Ÿè™•ç†å„ªåŒ–")
    print("âœ“ å½±ç‰‡éŒ„è£½åŒ¯å‡º")
    print("\næª¢æ¸¬æ–¹æ³•:")
    if tracker.yolo_available:
        print("  â–º YOLO (ä¸»è¦)")
    if MEDIAPIPE_AVAILABLE:
        print("  â–º MediaPipe (å‚™ç”¨)")
    print("  â–º Haar Cascade (å¾Œå‚™)")
    
    print("\næ“ä½œèªªæ˜:")
    print("  q - é€€å‡º")
    print("  +/- - èª¿æ•´å¼·åº¦")
    print("  1/2/3 - åˆ‡æ›æ•ˆæœ")
    print("  s - èª¿æ•´å®‰å…¨é‚Šç•Œ")
    print("  d - åˆ‡æ›æª¢æ¸¬æ–¹æ³•")
    print("  c - åˆ‡æ›å°å­©ä¿è­·æ¨¡å¼")
    print("  a - èª¿æ•´å¹´é½¡é–¾å€¼")
    print("  SPACE - æš«åœ/ç¹¼çºŒ")
    print("  r - é–‹å§‹/åœæ­¢éŒ„å½±")
    print("  o - é–‹å•Ÿè¼¸å‡ºè³‡æ–™å¤¾")
    
    # æ€§èƒ½ç›£æ§
    fps_counter = 0
    fps_timer = time.time()
    current_fps = 0
    
    # å¹€æ™‚é–“ç›£æ§
    frame_times = deque(maxlen=30)
    
    # æš«åœç‹€æ…‹
    paused = False
    
    while True:
        if not paused:
            frame_start = time.time()
            
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            display_frame = frame.copy()
            
            # äººè‡‰æª¢æ¸¬
            faces = tracker.update_face_detection(frame)
            
            # æ‡‰ç”¨é¦¬è³½å…‹
            display_frame = apply_smart_mosaic(display_frame, faces, mosaic_size, mosaic_style, tracker)
            
            # å¯«å…¥éŒ„å½±å¹€
            if recorder.recording:
                recorder.write_frame(display_frame)
            
            # æ€§èƒ½çµ±è¨ˆ
            frame_end = time.time()
            frame_time = frame_end - frame_start
            frame_times.append(frame_time)
            
            fps_counter += 1
            if fps_counter >= 15:
                current_fps = 15 / (time.time() - fps_timer)
                fps_timer = time.time()
                fps_counter = 0
            
            avg_frame_time = sum(frame_times) / len(frame_times) if frame_times else 0
        else:
            display_frame = frame.copy() if 'frame' in locals() else np.zeros((480, 640, 3), dtype=np.uint8)
        
        # é¡¯ç¤ºè³‡è¨Š
        info_texts = [
            f'Detection Method: {tracker.detection_method.upper()}',
            f'Detected Faces: {len(faces)}',
            f'FPS: {current_fps:.1f}',
            f'Processing Time: {avg_frame_time*1000:.1f}ms',
            f'Effect: {mosaic_style} ({mosaic_size})',
            f'Child Protection: {"Enabled" if tracker.child_protection_enabled else "Disabled"}',
        ]
        
        # éŒ„å½±ç‹€æ…‹è³‡è¨Š
        if recorder.recording:
            rec_info = recorder.get_recording_info()
            if rec_info:
                info_texts.extend([
                    f'ğŸ¬ Recording: {rec_info["filename"]}',
                    f'Duration: {rec_info["duration"]:.1f}s | Frames: {rec_info["frame_count"]}'
                ])
        else:
            info_texts.append('ğŸ“¹ Press R to start recording')
        
        if tracker.child_protection_enabled and DEEPFACE_AVAILABLE:
            info_texts.append(f'Age Threshold: {tracker.age_threshold} years')
            # é¡¯ç¤ºæª¢æ¸¬åˆ°çš„å¹´é½¡è³‡è¨Š
            detected_ages = []
            for face in faces[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                face_hash = tracker.get_face_hash(face)
                if face_hash in tracker.face_age_cache:
                    age = tracker.face_age_cache[face_hash]
                    if age is not None:
                        detected_ages.append(int(age))
            if detected_ages:
                info_texts.append(f'Detected Ages: {", ".join(map(str, detected_ages))}')
        
        info_texts.append(f'Status: {"Paused" if paused else "Running"}')
        
        y_offset = 20
        for text in info_texts:
            # éŒ„å½±æ™‚ä½¿ç”¨ç´…è‰²ï¼Œæš«åœæ™‚ä½¿ç”¨é»ƒè‰²ï¼Œæ­£å¸¸æ™‚ä½¿ç”¨ç¶ è‰²
            if recorder.recording and not paused:
                color = (0, 0, 255)  # ç´…è‰² - éŒ„å½±ä¸­
            elif paused:
                color = (0, 255, 255)  # é»ƒè‰² - æš«åœ
            else:
                color = (0, 255, 0)  # ç¶ è‰² - æ­£å¸¸
            
            cv2.putText(display_frame, text, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            y_offset += 18
        
        # éŒ„å½±æŒ‡ç¤ºå™¨
        if recorder.recording:
            # é–ƒçˆçš„éŒ„å½±åœ“é»
            if int(time.time() * 2) % 2:  # æ¯0.5ç§’é–ƒçˆ
                cv2.circle(display_frame, (display_frame.shape[1] - 30, 30), 10, (0, 0, 255), -1)
                cv2.putText(display_frame, "REC", (display_frame.shape[1] - 60, 50), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        cv2.imshow('é«˜æ€§èƒ½äººè‡‰é¦¬è³½å…‹ - YOLOv11n (å«éŒ„å½±)', display_frame)
        
        # æŒ‰éµè™•ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            # é€€å‡ºå‰åœæ­¢éŒ„å½±
            if recorder.recording:
                recorder.stop_recording()
            break
        elif key == ord('+') or key == ord('='):
            mosaic_size = max(3, mosaic_size - 2)
            print(f"é¦¬è³½å…‹å¼·åº¦: {mosaic_size}")
        elif key == ord('-'):
            mosaic_size = min(50, mosaic_size + 2)
            print(f"é¦¬è³½å…‹å¼·åº¦: {mosaic_size}")
        elif key == ord('1'):
            mosaic_style = 'pixelate'
            print("åƒç´ åŒ–é¦¬è³½å…‹")
        elif key == ord('2'):
            mosaic_style = 'blur'
            print("æ¨¡ç³Šæ•ˆæœ")
        elif key == ord('3'):
            mosaic_style = 'black'
            print("é»‘è‰²é®æ“‹")
        elif key == ord('s'):
            tracker.safety_margin = 1.5 if tracker.safety_margin < 1.4 else 1.2
            print(f"å®‰å…¨é‚Šç•Œ: {tracker.safety_margin:.1f}x")
        elif key == ord('d'):
            # åˆ‡æ›æª¢æ¸¬æ–¹æ³•
            methods = []
            if tracker.yolo_available:
                methods.append('yolo')
            if MEDIAPIPE_AVAILABLE:
                methods.append('mediapipe')
            methods.append('haar')  # Haar ç¸½æ˜¯å¯ç”¨
            
            if len(methods) > 1:
                current_idx = methods.index(tracker.detection_method) if tracker.detection_method in methods else 0
                next_idx = (current_idx + 1) % len(methods)
                tracker.detection_method = methods[next_idx]
                print(f"åˆ‡æ›åˆ° {tracker.detection_method.upper()} æª¢æ¸¬æ–¹æ³•")
            else:
                print(f"åªæœ‰ {tracker.detection_method.upper()} æª¢æ¸¬æ–¹æ³•å¯ç”¨")
        elif key == ord(' '):
            paused = not paused
            print("æš«åœ" if paused else "ç¹¼çºŒ")
        elif key == ord('r'):
            # éŒ„å½±æ§åˆ¶
            if recorder.recording:
                output_file = recorder.stop_recording()
                if output_file:
                    print(f"å½±ç‰‡å·²å„²å­˜è‡³: {output_file}")
            else:
                frame_size = (display_frame.shape[1], display_frame.shape[0])
                if recorder.start_recording(frame_size):
                    print("é–‹å§‹éŒ„å½±...")
                else:
                    print("éŒ„å½±å•Ÿå‹•å¤±æ•—")
        elif key == ord('o'):
            # é–‹å•Ÿè¼¸å‡ºè³‡æ–™å¤¾
            output_dir = recorder.output_dir
            if os.path.exists(output_dir):
                try:
                    # Windows
                    if os.name == 'nt':
                        os.startfile(output_dir)
                    print(f"å·²é–‹å•Ÿè¼¸å‡ºè³‡æ–™å¤¾: {output_dir}")
                except Exception as e:
                    print(f"ç„¡æ³•é–‹å•Ÿè³‡æ–™å¤¾: {e}")
                    print(f"æ‰‹å‹•è·¯å¾‘: {os.path.abspath(output_dir)}")
            else:
                print(f"è¼¸å‡ºè³‡æ–™å¤¾ä¸å­˜åœ¨: {output_dir}")
        elif key == ord('c'):
            # åˆ‡æ›å°å­©ä¿è­·æ¨¡å¼
            if DEEPFACE_AVAILABLE:
                tracker.child_protection_enabled = not tracker.child_protection_enabled
                print(f"å°å­©ä¿è­·æ¨¡å¼: {'é–‹å•Ÿ' if tracker.child_protection_enabled else 'é—œé–‰'}")
                if tracker.child_protection_enabled:
                    print(f"å°‡åªå° {tracker.age_threshold} æ­²ä»¥ä¸‹çš„è‡‰éƒ¨æ‡‰ç”¨é¦¬è³½å…‹")
                # æ¸…ç©ºå¹´é½¡ç·©å­˜
                tracker.face_age_cache.clear()
                tracker.last_age_detection.clear()
            else:
                print("DeepFace æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨å°å­©ä¿è­·åŠŸèƒ½")
                print("å®‰è£æ–¹å¼: pip install deepface")
        elif key == ord('a'):
            # èª¿æ•´å¹´é½¡é–¾å€¼
            if DEEPFACE_AVAILABLE:
                print(f"ç•¶å‰å¹´é½¡é–¾å€¼: {tracker.age_threshold}")
                print("è¼¸å…¥æ–°çš„å¹´é½¡é–¾å€¼ (å»ºè­° 16-21):")
                try:
                    # ç°¡å–®çš„è¼¸å…¥è™•ç†
                    age_input = ""
                    while True:
                        k = cv2.waitKey(0) & 0xFF
                        if k == 13:  # Enter
                            break
                        elif k == 8:  # Backspace
                            age_input = age_input[:-1]
                        elif 48 <= k <= 57:  # æ•¸å­—
                            age_input += chr(k)
                        elif k == 27:  # ESC
                            age_input = ""
                            break
                    
                    if age_input:
                        new_age = int(age_input)
                        if 1 <= new_age <= 100:
                            tracker.age_threshold = new_age
                            tracker.face_age_cache.clear()
                            tracker.last_age_detection.clear()
                            print(f"å¹´é½¡é–¾å€¼è¨­ç‚º: {tracker.age_threshold}")
                        else:
                            print("å¹´é½¡å¿…é ˆåœ¨ 1-100 ä¹‹é–“")
                except:
                    print("è¼¸å…¥ç„¡æ•ˆ")
    
    cap.release()
    cv2.destroyAllWindows()
    
    # æ¸…ç†è³‡æº
    if recorder.recording:
        recorder.stop_recording()

if __name__ == "__main__":
    main()